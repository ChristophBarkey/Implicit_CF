{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook for Pre-tuning of models. For this purpose a shallow train/test evaluation protocol is applied:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dataloading import DataLoader\n",
    "from eALS_adaptor import eALSAdaptor\n",
    "from implicit.evaluation import train_test_split, ranking_metrics_at_k\n",
    "from cv_py import CrossValidation\n",
    "\n",
    "%cd C:\\Users\\781110104\\OneDrive - Genpact\\Documents\\VSCode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'loc_agco_new.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\chris\\implicitCFrepo\\Implicit_CF\\Pre-selection_models.ipynb Zelle 4\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/c%3A/Users/chris/implicitCFrepo/Implicit_CF/Pre-selection_models.ipynb#ch0000003?line=0'>1</a>\u001b[0m user_item_co \u001b[39m=\u001b[39m dl\u001b[39m.\u001b[39;49mimport_data(\u001b[39m'\u001b[39;49m\u001b[39mAGCO\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mCO\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mdf\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/c%3A/Users/chris/implicitCFrepo/Implicit_CF/Pre-selection_models.ipynb#ch0000003?line=1'>2</a>\u001b[0m user_item_co_t \u001b[39m=\u001b[39m dl\u001b[39m.\u001b[39mimport_data(\u001b[39m'\u001b[39m\u001b[39mTEREX\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mCO\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdf\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/dataloading.py:39\u001b[0m, in \u001b[0;36mDataLoader.import_data\u001b[0;34m(self, OEM, file, return_type, clip)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39m#import pandas as pd\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[39mif\u001b[39;00m OEM \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mAGCO\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m---> 39\u001b[0m     agco_loc \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39mloc_agco_new.csv\u001b[39;49m\u001b[39m'\u001b[39;49m, sep \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39m|\u001b[39;49m\u001b[39m'\u001b[39;49m, low_memory\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     41\u001b[0m     \u001b[39mif\u001b[39;00m file \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mCO\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m     42\u001b[0m         agco_cod_18 \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39mcod_agco_new_2018.csv\u001b[39m\u001b[39m'\u001b[39m, sep \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m|\u001b[39m\u001b[39m'\u001b[39m, low_memory\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py:678\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    663\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    664\u001b[0m     dialect,\n\u001b[1;32m    665\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    674\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    675\u001b[0m )\n\u001b[1;32m    676\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 678\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    577\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py:932\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    929\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    931\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 932\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1216\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1212\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1213\u001b[0m \u001b[39m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m \u001b[39m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[39m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1216\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(  \u001b[39m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1217\u001b[0m     f,\n\u001b[1;32m   1218\u001b[0m     mode,\n\u001b[1;32m   1219\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1220\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1221\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1222\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1223\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1224\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1225\u001b[0m )\n\u001b[1;32m   1226\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1227\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/common.py:786\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    782\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    785\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 786\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    787\u001b[0m             handle,\n\u001b[1;32m    788\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    789\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    790\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    791\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    792\u001b[0m         )\n\u001b[1;32m    793\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    794\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    795\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'loc_agco_new.csv'"
     ]
    }
   ],
   "source": [
    "# loading the data\n",
    "user_item_co = dl.import_data('AGCO', 'CO', 'df')\n",
    "user_item_co_t = dl.import_data('TEREX', 'CO', 'df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove items with only one interaction\n",
    "user_item_filtered = dl.remove_low_interact_items(user_item_co, 1)\n",
    "user_item_filtered_t = dl.remove_low_interact_items(user_item_co_t, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale interaction data\n",
    "user_item_filtered_log = dl.log_scale_df(user_item_filtered, 0.01)\n",
    "user_item_filtered_log_t = dl.log_scale_df(user_item_filtered_t, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform to sparse matrix\n",
    "user_item_csr = dl.to_csr(user_item_filtered_log)\n",
    "user_item_csr_t = dl.to_csr(user_item_filtered_log_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply 80/20 train test split\n",
    "train, test = train_test_split(user_item_csr, 0.8, 22)\n",
    "train_t, test_t = train_test_split(user_item_csr_t, 0.8, 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CrossValidation(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train data again, only once for pre-tuning\n",
    "cal, val = train_test_split(train, 0.8, 22)\n",
    "cal_t, val_t = train_test_split(train_t, 0.8, 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tune iALS model for both OEMs\n",
    "space_iALS = {'factors' : [64], 'regularization' : [100, 120, 140], 'alpha' : [0.3, 0.4, 0.5], 'iterations' : [15]}\n",
    "space_iALS_t = {'factors' : [64], 'regularization' : [40, 60, 80], 'alpha' : [0.6, 0.7, 0.8], 'iterations' : [15]}\n",
    "hyper_ials = cv.hyperp_tuning_simple(test=val, train=cal, seed=22, param_space=space_iALS, model_class='iALS', exclude=test)\n",
    "hyper_ials_t = cv.hyperp_tuning_simple(test=val_t, train=cal_t, seed=22, param_space=space_iALS_t, model_class='iALS', exclude=test_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>factors</th>\n",
       "      <th>regularization</th>\n",
       "      <th>alpha</th>\n",
       "      <th>iterations</th>\n",
       "      <th>precision</th>\n",
       "      <th>map</th>\n",
       "      <th>ndcg</th>\n",
       "      <th>auc</th>\n",
       "      <th>mpr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64</td>\n",
       "      <td>60</td>\n",
       "      <td>0.7</td>\n",
       "      <td>15</td>\n",
       "      <td>0.5475</td>\n",
       "      <td>0.431271</td>\n",
       "      <td>0.572166</td>\n",
       "      <td>0.516070</td>\n",
       "      <td>0.122000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64</td>\n",
       "      <td>60</td>\n",
       "      <td>0.6</td>\n",
       "      <td>15</td>\n",
       "      <td>0.5400</td>\n",
       "      <td>0.424648</td>\n",
       "      <td>0.564252</td>\n",
       "      <td>0.515573</td>\n",
       "      <td>0.121715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>64</td>\n",
       "      <td>60</td>\n",
       "      <td>0.8</td>\n",
       "      <td>15</td>\n",
       "      <td>0.5400</td>\n",
       "      <td>0.423000</td>\n",
       "      <td>0.564975</td>\n",
       "      <td>0.515800</td>\n",
       "      <td>0.121559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>64</td>\n",
       "      <td>80</td>\n",
       "      <td>0.8</td>\n",
       "      <td>15</td>\n",
       "      <td>0.5375</td>\n",
       "      <td>0.412792</td>\n",
       "      <td>0.556747</td>\n",
       "      <td>0.515777</td>\n",
       "      <td>0.122598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64</td>\n",
       "      <td>40</td>\n",
       "      <td>0.7</td>\n",
       "      <td>15</td>\n",
       "      <td>0.5300</td>\n",
       "      <td>0.416848</td>\n",
       "      <td>0.559729</td>\n",
       "      <td>0.515636</td>\n",
       "      <td>0.128754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>64</td>\n",
       "      <td>80</td>\n",
       "      <td>0.7</td>\n",
       "      <td>15</td>\n",
       "      <td>0.5300</td>\n",
       "      <td>0.406903</td>\n",
       "      <td>0.551875</td>\n",
       "      <td>0.515400</td>\n",
       "      <td>0.123062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64</td>\n",
       "      <td>40</td>\n",
       "      <td>0.8</td>\n",
       "      <td>15</td>\n",
       "      <td>0.5225</td>\n",
       "      <td>0.410191</td>\n",
       "      <td>0.553879</td>\n",
       "      <td>0.515314</td>\n",
       "      <td>0.130178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>64</td>\n",
       "      <td>80</td>\n",
       "      <td>0.6</td>\n",
       "      <td>15</td>\n",
       "      <td>0.5225</td>\n",
       "      <td>0.402790</td>\n",
       "      <td>0.551472</td>\n",
       "      <td>0.515196</td>\n",
       "      <td>0.125526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64</td>\n",
       "      <td>40</td>\n",
       "      <td>0.6</td>\n",
       "      <td>15</td>\n",
       "      <td>0.5175</td>\n",
       "      <td>0.417861</td>\n",
       "      <td>0.553184</td>\n",
       "      <td>0.515231</td>\n",
       "      <td>0.127861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   factors  regularization  alpha  iterations  precision       map      ndcg  \\\n",
       "4       64              60    0.7          15     0.5475  0.431271  0.572166   \n",
       "3       64              60    0.6          15     0.5400  0.424648  0.564252   \n",
       "5       64              60    0.8          15     0.5400  0.423000  0.564975   \n",
       "8       64              80    0.8          15     0.5375  0.412792  0.556747   \n",
       "1       64              40    0.7          15     0.5300  0.416848  0.559729   \n",
       "7       64              80    0.7          15     0.5300  0.406903  0.551875   \n",
       "2       64              40    0.8          15     0.5225  0.410191  0.553879   \n",
       "6       64              80    0.6          15     0.5225  0.402790  0.551472   \n",
       "0       64              40    0.6          15     0.5175  0.417861  0.553184   \n",
       "\n",
       "        auc       mpr  \n",
       "4  0.516070  0.122000  \n",
       "3  0.515573  0.121715  \n",
       "5  0.515800  0.121559  \n",
       "8  0.515777  0.122598  \n",
       "1  0.515636  0.128754  \n",
       "7  0.515400  0.123062  \n",
       "2  0.515314  0.130178  \n",
       "6  0.515196  0.125526  \n",
       "0  0.515231  0.127861  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_ials_t.sort_values(by=['precision'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting type of user_items to <class 'numpy.float32'>\n",
      "converting type of user_items to <class 'numpy.float32'>\n",
      "converting type of user_items to <class 'numpy.float32'>\n",
      "converting type of user_items to <class 'numpy.float32'>\n",
      "converting type of user_items to <class 'numpy.float32'>\n",
      "converting type of user_items to <class 'numpy.float32'>\n",
      "converting type of user_items to <class 'numpy.float32'>\n",
      "converting type of user_items to <class 'numpy.float32'>\n",
      "converting type of user_items to <class 'numpy.float32'>\n",
      "converting type of user_items to <class 'numpy.float32'>\n",
      "converting type of user_items to <class 'numpy.float32'>\n",
      "converting type of user_items to <class 'numpy.float32'>\n",
      "converting type of user_items to <class 'numpy.float32'>\n",
      "converting type of user_items to <class 'numpy.float32'>\n",
      "converting type of user_items to <class 'numpy.float32'>\n",
      "converting type of user_items to <class 'numpy.float32'>\n",
      "converting type of user_items to <class 'numpy.float32'>\n",
      "converting type of user_items to <class 'numpy.float32'>\n",
      "converting type of user_items to <class 'numpy.float32'>\n",
      "converting type of user_items to <class 'numpy.float32'>\n",
      "converting type of user_items to <class 'numpy.float32'>\n",
      "converting type of user_items to <class 'numpy.float32'>\n",
      "converting type of user_items to <class 'numpy.float32'>\n",
      "converting type of user_items to <class 'numpy.float32'>\n",
      "converting type of user_items to <class 'numpy.float32'>\n",
      "converting type of user_items to <class 'numpy.float32'>\n",
      "converting type of user_items to <class 'numpy.float32'>\n"
     ]
    }
   ],
   "source": [
    "# tune eALS model for both OEMs\n",
    "space_eALS = {'factors' : [64], 'regularization' : [200, 250, 300], 'alpha' : [0.1, 0.2, 0.3], 'w0' : [25000, 30000, 35000], 'iterations' : [15]}\n",
    "space_eALS_t = {'factors' : [64], 'regularization' : [10], 'alpha' : [0.2], 'w0' : [1500], 'iterations' : [15]}\n",
    "hyper_eals = cv.hyperp_tuning_simple(test=val, train=cal, seed=22, param_space=space_eALS, model_class='eALS', exclude=test)\n",
    "hyper_eals_t = cv.hyperp_tuning_simple(test=val_t, train=cal_t, seed=22, param_space=space_eALS_t, model_class='eALS', exclude=test_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>factors</th>\n",
       "      <th>regularization</th>\n",
       "      <th>alpha</th>\n",
       "      <th>w0</th>\n",
       "      <th>iterations</th>\n",
       "      <th>precision</th>\n",
       "      <th>map</th>\n",
       "      <th>ndcg</th>\n",
       "      <th>auc</th>\n",
       "      <th>mpr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>64</td>\n",
       "      <td>250</td>\n",
       "      <td>0.1</td>\n",
       "      <td>35000</td>\n",
       "      <td>15</td>\n",
       "      <td>0.856766</td>\n",
       "      <td>0.802814</td>\n",
       "      <td>0.867464</td>\n",
       "      <td>0.505434</td>\n",
       "      <td>0.083007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>64</td>\n",
       "      <td>250</td>\n",
       "      <td>0.2</td>\n",
       "      <td>30000</td>\n",
       "      <td>15</td>\n",
       "      <td>0.856106</td>\n",
       "      <td>0.802382</td>\n",
       "      <td>0.866741</td>\n",
       "      <td>0.505371</td>\n",
       "      <td>0.082499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>64</td>\n",
       "      <td>250</td>\n",
       "      <td>0.1</td>\n",
       "      <td>30000</td>\n",
       "      <td>15</td>\n",
       "      <td>0.856106</td>\n",
       "      <td>0.802082</td>\n",
       "      <td>0.867305</td>\n",
       "      <td>0.505427</td>\n",
       "      <td>0.083066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>64</td>\n",
       "      <td>250</td>\n",
       "      <td>0.2</td>\n",
       "      <td>35000</td>\n",
       "      <td>15</td>\n",
       "      <td>0.856106</td>\n",
       "      <td>0.803282</td>\n",
       "      <td>0.867282</td>\n",
       "      <td>0.505361</td>\n",
       "      <td>0.082594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64</td>\n",
       "      <td>200</td>\n",
       "      <td>0.1</td>\n",
       "      <td>35000</td>\n",
       "      <td>15</td>\n",
       "      <td>0.855446</td>\n",
       "      <td>0.801305</td>\n",
       "      <td>0.867282</td>\n",
       "      <td>0.505389</td>\n",
       "      <td>0.083742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64</td>\n",
       "      <td>200</td>\n",
       "      <td>0.1</td>\n",
       "      <td>30000</td>\n",
       "      <td>15</td>\n",
       "      <td>0.853465</td>\n",
       "      <td>0.800688</td>\n",
       "      <td>0.866775</td>\n",
       "      <td>0.505360</td>\n",
       "      <td>0.082946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>64</td>\n",
       "      <td>250</td>\n",
       "      <td>0.2</td>\n",
       "      <td>25000</td>\n",
       "      <td>15</td>\n",
       "      <td>0.853465</td>\n",
       "      <td>0.798655</td>\n",
       "      <td>0.865144</td>\n",
       "      <td>0.505388</td>\n",
       "      <td>0.082631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64</td>\n",
       "      <td>200</td>\n",
       "      <td>0.1</td>\n",
       "      <td>25000</td>\n",
       "      <td>15</td>\n",
       "      <td>0.852475</td>\n",
       "      <td>0.799589</td>\n",
       "      <td>0.866262</td>\n",
       "      <td>0.505350</td>\n",
       "      <td>0.082380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>64</td>\n",
       "      <td>250</td>\n",
       "      <td>0.3</td>\n",
       "      <td>35000</td>\n",
       "      <td>15</td>\n",
       "      <td>0.852145</td>\n",
       "      <td>0.798158</td>\n",
       "      <td>0.864031</td>\n",
       "      <td>0.505385</td>\n",
       "      <td>0.082622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>64</td>\n",
       "      <td>200</td>\n",
       "      <td>0.2</td>\n",
       "      <td>35000</td>\n",
       "      <td>15</td>\n",
       "      <td>0.851815</td>\n",
       "      <td>0.799207</td>\n",
       "      <td>0.864901</td>\n",
       "      <td>0.505332</td>\n",
       "      <td>0.084177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>64</td>\n",
       "      <td>250</td>\n",
       "      <td>0.3</td>\n",
       "      <td>30000</td>\n",
       "      <td>15</td>\n",
       "      <td>0.851485</td>\n",
       "      <td>0.797352</td>\n",
       "      <td>0.863587</td>\n",
       "      <td>0.505373</td>\n",
       "      <td>0.082336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64</td>\n",
       "      <td>200</td>\n",
       "      <td>0.2</td>\n",
       "      <td>30000</td>\n",
       "      <td>15</td>\n",
       "      <td>0.850825</td>\n",
       "      <td>0.797710</td>\n",
       "      <td>0.863991</td>\n",
       "      <td>0.505344</td>\n",
       "      <td>0.083106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64</td>\n",
       "      <td>200</td>\n",
       "      <td>0.2</td>\n",
       "      <td>25000</td>\n",
       "      <td>15</td>\n",
       "      <td>0.850825</td>\n",
       "      <td>0.797921</td>\n",
       "      <td>0.864373</td>\n",
       "      <td>0.505340</td>\n",
       "      <td>0.082237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>64</td>\n",
       "      <td>200</td>\n",
       "      <td>0.3</td>\n",
       "      <td>35000</td>\n",
       "      <td>15</td>\n",
       "      <td>0.850495</td>\n",
       "      <td>0.796906</td>\n",
       "      <td>0.863070</td>\n",
       "      <td>0.505325</td>\n",
       "      <td>0.085113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>64</td>\n",
       "      <td>250</td>\n",
       "      <td>0.3</td>\n",
       "      <td>25000</td>\n",
       "      <td>15</td>\n",
       "      <td>0.850165</td>\n",
       "      <td>0.796884</td>\n",
       "      <td>0.862673</td>\n",
       "      <td>0.505335</td>\n",
       "      <td>0.082293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>64</td>\n",
       "      <td>250</td>\n",
       "      <td>0.1</td>\n",
       "      <td>25000</td>\n",
       "      <td>15</td>\n",
       "      <td>0.849175</td>\n",
       "      <td>0.793323</td>\n",
       "      <td>0.861880</td>\n",
       "      <td>0.505403</td>\n",
       "      <td>0.083345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>64</td>\n",
       "      <td>200</td>\n",
       "      <td>0.3</td>\n",
       "      <td>30000</td>\n",
       "      <td>15</td>\n",
       "      <td>0.848845</td>\n",
       "      <td>0.793983</td>\n",
       "      <td>0.861220</td>\n",
       "      <td>0.505334</td>\n",
       "      <td>0.083763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>64</td>\n",
       "      <td>200</td>\n",
       "      <td>0.3</td>\n",
       "      <td>25000</td>\n",
       "      <td>15</td>\n",
       "      <td>0.848185</td>\n",
       "      <td>0.793676</td>\n",
       "      <td>0.861486</td>\n",
       "      <td>0.505348</td>\n",
       "      <td>0.082568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>64</td>\n",
       "      <td>300</td>\n",
       "      <td>0.2</td>\n",
       "      <td>35000</td>\n",
       "      <td>15</td>\n",
       "      <td>0.847525</td>\n",
       "      <td>0.792398</td>\n",
       "      <td>0.859977</td>\n",
       "      <td>0.505333</td>\n",
       "      <td>0.083836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>64</td>\n",
       "      <td>300</td>\n",
       "      <td>0.3</td>\n",
       "      <td>30000</td>\n",
       "      <td>15</td>\n",
       "      <td>0.847525</td>\n",
       "      <td>0.792009</td>\n",
       "      <td>0.859483</td>\n",
       "      <td>0.505331</td>\n",
       "      <td>0.083659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>64</td>\n",
       "      <td>300</td>\n",
       "      <td>0.2</td>\n",
       "      <td>30000</td>\n",
       "      <td>15</td>\n",
       "      <td>0.846535</td>\n",
       "      <td>0.790134</td>\n",
       "      <td>0.858749</td>\n",
       "      <td>0.505330</td>\n",
       "      <td>0.084220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>64</td>\n",
       "      <td>300</td>\n",
       "      <td>0.1</td>\n",
       "      <td>35000</td>\n",
       "      <td>15</td>\n",
       "      <td>0.845875</td>\n",
       "      <td>0.788288</td>\n",
       "      <td>0.857444</td>\n",
       "      <td>0.505351</td>\n",
       "      <td>0.084654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>64</td>\n",
       "      <td>300</td>\n",
       "      <td>0.3</td>\n",
       "      <td>25000</td>\n",
       "      <td>15</td>\n",
       "      <td>0.844554</td>\n",
       "      <td>0.787442</td>\n",
       "      <td>0.856770</td>\n",
       "      <td>0.505331</td>\n",
       "      <td>0.084192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>64</td>\n",
       "      <td>300</td>\n",
       "      <td>0.3</td>\n",
       "      <td>35000</td>\n",
       "      <td>15</td>\n",
       "      <td>0.843894</td>\n",
       "      <td>0.791067</td>\n",
       "      <td>0.858102</td>\n",
       "      <td>0.505280</td>\n",
       "      <td>0.083411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>64</td>\n",
       "      <td>300</td>\n",
       "      <td>0.2</td>\n",
       "      <td>25000</td>\n",
       "      <td>15</td>\n",
       "      <td>0.842904</td>\n",
       "      <td>0.784564</td>\n",
       "      <td>0.855059</td>\n",
       "      <td>0.505316</td>\n",
       "      <td>0.084886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>64</td>\n",
       "      <td>300</td>\n",
       "      <td>0.1</td>\n",
       "      <td>30000</td>\n",
       "      <td>15</td>\n",
       "      <td>0.842244</td>\n",
       "      <td>0.785241</td>\n",
       "      <td>0.855454</td>\n",
       "      <td>0.505324</td>\n",
       "      <td>0.085151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>64</td>\n",
       "      <td>300</td>\n",
       "      <td>0.1</td>\n",
       "      <td>25000</td>\n",
       "      <td>15</td>\n",
       "      <td>0.837294</td>\n",
       "      <td>0.778217</td>\n",
       "      <td>0.850895</td>\n",
       "      <td>0.505309</td>\n",
       "      <td>0.085930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    factors  regularization  alpha     w0  iterations  precision       map  \\\n",
       "11       64             250    0.1  35000          15   0.856766  0.802814   \n",
       "13       64             250    0.2  30000          15   0.856106  0.802382   \n",
       "10       64             250    0.1  30000          15   0.856106  0.802082   \n",
       "14       64             250    0.2  35000          15   0.856106  0.803282   \n",
       "2        64             200    0.1  35000          15   0.855446  0.801305   \n",
       "1        64             200    0.1  30000          15   0.853465  0.800688   \n",
       "12       64             250    0.2  25000          15   0.853465  0.798655   \n",
       "0        64             200    0.1  25000          15   0.852475  0.799589   \n",
       "17       64             250    0.3  35000          15   0.852145  0.798158   \n",
       "5        64             200    0.2  35000          15   0.851815  0.799207   \n",
       "16       64             250    0.3  30000          15   0.851485  0.797352   \n",
       "4        64             200    0.2  30000          15   0.850825  0.797710   \n",
       "3        64             200    0.2  25000          15   0.850825  0.797921   \n",
       "8        64             200    0.3  35000          15   0.850495  0.796906   \n",
       "15       64             250    0.3  25000          15   0.850165  0.796884   \n",
       "9        64             250    0.1  25000          15   0.849175  0.793323   \n",
       "7        64             200    0.3  30000          15   0.848845  0.793983   \n",
       "6        64             200    0.3  25000          15   0.848185  0.793676   \n",
       "23       64             300    0.2  35000          15   0.847525  0.792398   \n",
       "25       64             300    0.3  30000          15   0.847525  0.792009   \n",
       "22       64             300    0.2  30000          15   0.846535  0.790134   \n",
       "20       64             300    0.1  35000          15   0.845875  0.788288   \n",
       "24       64             300    0.3  25000          15   0.844554  0.787442   \n",
       "26       64             300    0.3  35000          15   0.843894  0.791067   \n",
       "21       64             300    0.2  25000          15   0.842904  0.784564   \n",
       "19       64             300    0.1  30000          15   0.842244  0.785241   \n",
       "18       64             300    0.1  25000          15   0.837294  0.778217   \n",
       "\n",
       "        ndcg       auc       mpr  \n",
       "11  0.867464  0.505434  0.083007  \n",
       "13  0.866741  0.505371  0.082499  \n",
       "10  0.867305  0.505427  0.083066  \n",
       "14  0.867282  0.505361  0.082594  \n",
       "2   0.867282  0.505389  0.083742  \n",
       "1   0.866775  0.505360  0.082946  \n",
       "12  0.865144  0.505388  0.082631  \n",
       "0   0.866262  0.505350  0.082380  \n",
       "17  0.864031  0.505385  0.082622  \n",
       "5   0.864901  0.505332  0.084177  \n",
       "16  0.863587  0.505373  0.082336  \n",
       "4   0.863991  0.505344  0.083106  \n",
       "3   0.864373  0.505340  0.082237  \n",
       "8   0.863070  0.505325  0.085113  \n",
       "15  0.862673  0.505335  0.082293  \n",
       "9   0.861880  0.505403  0.083345  \n",
       "7   0.861220  0.505334  0.083763  \n",
       "6   0.861486  0.505348  0.082568  \n",
       "23  0.859977  0.505333  0.083836  \n",
       "25  0.859483  0.505331  0.083659  \n",
       "22  0.858749  0.505330  0.084220  \n",
       "20  0.857444  0.505351  0.084654  \n",
       "24  0.856770  0.505331  0.084192  \n",
       "26  0.858102  0.505280  0.083411  \n",
       "21  0.855059  0.505316  0.084886  \n",
       "19  0.855454  0.505324  0.085151  \n",
       "18  0.850895  0.505309  0.085930  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_eals.sort_values(by=['precision'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tune BPR model for both OEMs\n",
    "space_BPR = {'factors' : [64], 'regularization' : [0.01, 0.05, 0.1], 'learning_rate' : [0.005, 0.01, 0.03, 0.05], 'iterations' : [15]}\n",
    "space_BPR_t = {'factors' : [64], 'regularization' : [0.03, 0.05, 0.07], 'learning_rate' : [0.03, 0.04, 0.05], 'iterations' : [15]}\n",
    "hyper_bpr = cv.hyperp_tuning_simple(test=val, train=cal, seed=22, param_space=space_BPR, model_class='BPR', exclude=test)\n",
    "hyper_bpr_t = cv.hyperp_tuning_simple(test=val_t, train=cal_t, seed=22, param_space=space_BPR_t, model_class='BPR', exclude=test_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>factors</th>\n",
       "      <th>regularization</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>iterations</th>\n",
       "      <th>precision</th>\n",
       "      <th>map</th>\n",
       "      <th>ndcg</th>\n",
       "      <th>auc</th>\n",
       "      <th>mpr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>64</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.04</td>\n",
       "      <td>15</td>\n",
       "      <td>0.3900</td>\n",
       "      <td>0.256441</td>\n",
       "      <td>0.403107</td>\n",
       "      <td>0.508503</td>\n",
       "      <td>0.116047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>64</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.05</td>\n",
       "      <td>15</td>\n",
       "      <td>0.3875</td>\n",
       "      <td>0.248703</td>\n",
       "      <td>0.397436</td>\n",
       "      <td>0.508647</td>\n",
       "      <td>0.118413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>64</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.03</td>\n",
       "      <td>15</td>\n",
       "      <td>0.3775</td>\n",
       "      <td>0.261830</td>\n",
       "      <td>0.405805</td>\n",
       "      <td>0.508523</td>\n",
       "      <td>0.132994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>64</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>15</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.238101</td>\n",
       "      <td>0.383687</td>\n",
       "      <td>0.507968</td>\n",
       "      <td>0.112722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>64</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.04</td>\n",
       "      <td>15</td>\n",
       "      <td>0.3675</td>\n",
       "      <td>0.251628</td>\n",
       "      <td>0.393997</td>\n",
       "      <td>0.508289</td>\n",
       "      <td>0.130743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>15</td>\n",
       "      <td>0.3650</td>\n",
       "      <td>0.234539</td>\n",
       "      <td>0.377510</td>\n",
       "      <td>0.507725</td>\n",
       "      <td>0.111900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>64</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.03</td>\n",
       "      <td>15</td>\n",
       "      <td>0.3550</td>\n",
       "      <td>0.242092</td>\n",
       "      <td>0.375757</td>\n",
       "      <td>0.507113</td>\n",
       "      <td>0.157160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>64</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>15</td>\n",
       "      <td>0.3550</td>\n",
       "      <td>0.241122</td>\n",
       "      <td>0.374548</td>\n",
       "      <td>0.507521</td>\n",
       "      <td>0.144177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>64</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.04</td>\n",
       "      <td>15</td>\n",
       "      <td>0.3475</td>\n",
       "      <td>0.238117</td>\n",
       "      <td>0.361746</td>\n",
       "      <td>0.507167</td>\n",
       "      <td>0.178801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>15</td>\n",
       "      <td>0.3425</td>\n",
       "      <td>0.214839</td>\n",
       "      <td>0.360217</td>\n",
       "      <td>0.507562</td>\n",
       "      <td>0.110371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>15</td>\n",
       "      <td>0.3325</td>\n",
       "      <td>0.205499</td>\n",
       "      <td>0.347163</td>\n",
       "      <td>0.507539</td>\n",
       "      <td>0.107814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>15</td>\n",
       "      <td>0.2175</td>\n",
       "      <td>0.141698</td>\n",
       "      <td>0.225861</td>\n",
       "      <td>0.503692</td>\n",
       "      <td>0.172692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>64</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.03</td>\n",
       "      <td>15</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.059633</td>\n",
       "      <td>0.136398</td>\n",
       "      <td>0.502280</td>\n",
       "      <td>0.345509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0225</td>\n",
       "      <td>0.009236</td>\n",
       "      <td>0.027268</td>\n",
       "      <td>0.500767</td>\n",
       "      <td>0.385344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>64</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0225</td>\n",
       "      <td>0.009236</td>\n",
       "      <td>0.027268</td>\n",
       "      <td>0.500767</td>\n",
       "      <td>0.387036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>64</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0225</td>\n",
       "      <td>0.008819</td>\n",
       "      <td>0.026547</td>\n",
       "      <td>0.500767</td>\n",
       "      <td>0.387606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    factors  regularization  learning_rate  iterations  precision       map  \\\n",
       "6        64            0.05           0.04          15     0.3900  0.256441   \n",
       "11       64            0.07           0.05          15     0.3875  0.248703   \n",
       "5        64            0.05           0.03          15     0.3775  0.261830   \n",
       "7        64            0.05           0.05          15     0.3750  0.238101   \n",
       "10       64            0.07           0.04          15     0.3675  0.251628   \n",
       "1        64            0.01           0.03          15     0.3650  0.234539   \n",
       "9        64            0.07           0.03          15     0.3550  0.242092   \n",
       "15       64            0.10           0.05          15     0.3550  0.241122   \n",
       "14       64            0.10           0.04          15     0.3475  0.238117   \n",
       "2        64            0.01           0.04          15     0.3425  0.214839   \n",
       "3        64            0.01           0.05          15     0.3325  0.205499   \n",
       "0        64            0.01           0.01          15     0.2175  0.141698   \n",
       "13       64            0.10           0.03          15     0.1250  0.059633   \n",
       "4        64            0.05           0.01          15     0.0225  0.009236   \n",
       "8        64            0.07           0.01          15     0.0225  0.009236   \n",
       "12       64            0.10           0.01          15     0.0225  0.008819   \n",
       "\n",
       "        ndcg       auc       mpr  \n",
       "6   0.403107  0.508503  0.116047  \n",
       "11  0.397436  0.508647  0.118413  \n",
       "5   0.405805  0.508523  0.132994  \n",
       "7   0.383687  0.507968  0.112722  \n",
       "10  0.393997  0.508289  0.130743  \n",
       "1   0.377510  0.507725  0.111900  \n",
       "9   0.375757  0.507113  0.157160  \n",
       "15  0.374548  0.507521  0.144177  \n",
       "14  0.361746  0.507167  0.178801  \n",
       "2   0.360217  0.507562  0.110371  \n",
       "3   0.347163  0.507539  0.107814  \n",
       "0   0.225861  0.503692  0.172692  \n",
       "13  0.136398  0.502280  0.345509  \n",
       "4   0.027268  0.500767  0.385344  \n",
       "8   0.027268  0.500767  0.387036  \n",
       "12  0.026547  0.500767  0.387606  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_bpr_t.sort_values(by=['precision'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # tune LMF model for both OEMs\n",
    "space_LMF = {'factors' : [64], 'regularization' : [10, 20, 30, 40, 50], 'learning_rate' : [0.3, 0.5, 0.7, 1.0, 2.0], 'iterations' : [15], 'neg_prop': [10, 20, 30]}\n",
    "space_LMF_t = {'factors' : [64], 'regularization' : [10, 20, 30, 40, 50], 'learning_rate' : [0.3, 0.5, 0.7, 1.0, 2.0], 'iterations' : [15], 'neg_prop': [0.5, 1, 2, 5, 10]}\n",
    "hyper_lmf = cv.hyperp_tuning_simple(test=val, train=cal, seed=22, param_space=space_LMF, model_class='LMF', exclude=test)\n",
    "hyper_lmf_t = cv.hyperp_tuning_simple(test=val_t, train=cal_t, seed=22, param_space=space_LMF_t, model_class='LMF', exclude=test_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>factors</th>\n",
       "      <th>regularization</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>iterations</th>\n",
       "      <th>neg_prop</th>\n",
       "      <th>precision</th>\n",
       "      <th>map</th>\n",
       "      <th>ndcg</th>\n",
       "      <th>auc</th>\n",
       "      <th>mpr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>64</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4600</td>\n",
       "      <td>0.346414</td>\n",
       "      <td>0.469798</td>\n",
       "      <td>0.510447</td>\n",
       "      <td>0.211272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>64</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3875</td>\n",
       "      <td>0.265012</td>\n",
       "      <td>0.391519</td>\n",
       "      <td>0.508147</td>\n",
       "      <td>0.168905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>64</td>\n",
       "      <td>20</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2725</td>\n",
       "      <td>0.136900</td>\n",
       "      <td>0.256487</td>\n",
       "      <td>0.506580</td>\n",
       "      <td>0.171952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>64</td>\n",
       "      <td>20</td>\n",
       "      <td>0.7</td>\n",
       "      <td>15</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2550</td>\n",
       "      <td>0.136568</td>\n",
       "      <td>0.248284</td>\n",
       "      <td>0.505231</td>\n",
       "      <td>0.172220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>64</td>\n",
       "      <td>40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2550</td>\n",
       "      <td>0.121686</td>\n",
       "      <td>0.225077</td>\n",
       "      <td>0.505348</td>\n",
       "      <td>0.255528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>64</td>\n",
       "      <td>40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0225</td>\n",
       "      <td>0.004964</td>\n",
       "      <td>0.018138</td>\n",
       "      <td>0.500073</td>\n",
       "      <td>0.442797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>64</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.010670</td>\n",
       "      <td>0.027186</td>\n",
       "      <td>0.500089</td>\n",
       "      <td>0.297611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>64</td>\n",
       "      <td>50</td>\n",
       "      <td>0.7</td>\n",
       "      <td>15</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.004625</td>\n",
       "      <td>0.016424</td>\n",
       "      <td>0.499974</td>\n",
       "      <td>0.396915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>64</td>\n",
       "      <td>20</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.005214</td>\n",
       "      <td>0.017547</td>\n",
       "      <td>0.499952</td>\n",
       "      <td>0.470872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>64</td>\n",
       "      <td>40</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.003413</td>\n",
       "      <td>0.010649</td>\n",
       "      <td>0.499839</td>\n",
       "      <td>0.450217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     factors  regularization  learning_rate  iterations  neg_prop  precision  \\\n",
       "65        64              30            1.0          15       0.5     0.4600   \n",
       "40        64              20            1.0          15       0.5     0.3875   \n",
       "45        64              20            2.0          15       0.5     0.2725   \n",
       "35        64              20            0.7          15       0.5     0.2550   \n",
       "90        64              40            1.0          15       0.5     0.2550   \n",
       "..       ...             ...            ...         ...       ...        ...   \n",
       "93        64              40            1.0          15       5.0     0.0225   \n",
       "106       64              50            0.5          15       1.0     0.0200   \n",
       "113       64              50            0.7          15       5.0     0.0200   \n",
       "48        64              20            2.0          15       5.0     0.0200   \n",
       "99        64              40            2.0          15      10.0     0.0100   \n",
       "\n",
       "          map      ndcg       auc       mpr  \n",
       "65   0.346414  0.469798  0.510447  0.211272  \n",
       "40   0.265012  0.391519  0.508147  0.168905  \n",
       "45   0.136900  0.256487  0.506580  0.171952  \n",
       "35   0.136568  0.248284  0.505231  0.172220  \n",
       "90   0.121686  0.225077  0.505348  0.255528  \n",
       "..        ...       ...       ...       ...  \n",
       "93   0.004964  0.018138  0.500073  0.442797  \n",
       "106  0.010670  0.027186  0.500089  0.297611  \n",
       "113  0.004625  0.016424  0.499974  0.396915  \n",
       "48   0.005214  0.017547  0.499952  0.470872  \n",
       "99   0.003413  0.010649  0.499839  0.450217  \n",
       "\n",
       "[125 rows x 10 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_lmf_t.sort_values(by=['precision'], ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b4efcf30d150067e76aa0880eb47772143c44e1fc3c522760740bd759ef99df4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
