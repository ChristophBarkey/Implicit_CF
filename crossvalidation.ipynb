{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from implicit.evaluation import train_test_split, ranking_metrics_at_k\n",
    "from implicit.datasets.movielens import get_movielens\n",
    "import implicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossValidation:\n",
    "    \n",
    "    def __init__(self, user_item, k):\n",
    "        self.user_item = user_item\n",
    "        self.k = k\n",
    "\n",
    "    def mpr_per_user(self, model, train, test, num_recs, user):\n",
    "        recommended_items = model.recommend(user_items=train[user], userid=user, filter_already_liked_items=True, N = num_recs)[0]\n",
    "        test_items = test[user].nonzero()[1]\n",
    "        test_items_in_list = test_items[np.isin(test_items, recommended_items)]\n",
    "        if len(test_items_in_list) == 0:\n",
    "            return 0.5\n",
    "        recommended_indices = recommended_items.argsort()\n",
    "        hit_indices = recommended_indices[np.searchsorted(recommended_items[recommended_indices], test_items_in_list)]\n",
    "        #return (np.sum(hit_indices) / num_recs) / len(hit_indices)\n",
    "        return np.mean(hit_indices / num_recs)\n",
    "   \n",
    "    def calc_mpr(self, model, train, test):\n",
    "        mprs = []\n",
    "        for u in range(self.user_item.shape[0]) :\n",
    "            mpr = self.mpr_per_user(model, train, test, self.user_item.shape[1], u)\n",
    "            mprs.append(mpr)\n",
    "        return {'mpr' : np.mean(mprs)} \n",
    "   \n",
    "    def evaluate_model(self, model, train, test, k):\n",
    "        metrics = ranking_metrics_at_k(model, train, test, K=k)\n",
    "        mpr = self.calc_mpr(model, train, test)\n",
    "        metrics.update(mpr)\n",
    "        return pd.DataFrame(metrics, index=['metrics@'+str(k)])  \n",
    "   \n",
    "    def split_k_fold(self) :\n",
    "        split_matrix = self.user_item\n",
    "        return_dict = {}\n",
    "        return_dict_train = {}\n",
    "        for i in range(self.k-1):\n",
    "            train_temp, test_temp = train_test_split(split_matrix, train_percentage=((self.k-(i+1))/(self.k-i)))\n",
    "            return_dict[str(i)] = test_temp\n",
    "            if i == 0:\n",
    "                return_dict_train[str(i)] = train_temp\n",
    "                rest = test_temp\n",
    "            else:\n",
    "                return_dict_train[str(i)] = (train_temp + rest)\n",
    "                rest = (rest + test_temp)\n",
    "            if i == (self.k-2):\n",
    "                return_dict[str(i+1)] = train_temp\n",
    "                return_dict_train[str(i+1)] = rest\n",
    "            split_matrix = train_temp\n",
    "        return (return_dict, return_dict_train)\n",
    "\n",
    "\n",
    "    def k_fold_eval(self, test, train, model, alpha) :\n",
    "        for i in range(len(test)) :\n",
    "            model = model\n",
    "            test_temp = test[str(i)]\n",
    "            train_temp = train[str(i)]\n",
    "            print(test_temp.nnz)\n",
    "            print(train_temp.nnz)\n",
    "            model.fit(train_temp * alpha)\n",
    "            m = self.evaluate_model(model, train_temp, test_temp, 10)\n",
    "            if i == 0:\n",
    "                df = m\n",
    "            else :\n",
    "                df = pd.concat((df, m), axis=0)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies1, ratings1 = get_movielens(\"1M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings1_t = ratings1.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validation = CrossValidation(ratings1_t, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = cross_validation.split_k_fold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "als = implicit.als.AlternatingLeastSquares(factors=128, regularization=0.01, num_threads=4, use_cg=True, use_native=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800265\n",
      "199944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:04<00:00,  3.40it/s]\n",
      "100%|██████████| 6040/6040 [00:00<00:00, 9948.28it/s] \n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "799976\n",
      "200233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:04<00:00,  3.53it/s]\n",
      "100%|██████████| 6040/6040 [00:00<00:00, 10575.56it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800803\n",
      "199406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:04<00:00,  3.49it/s]\n",
      "100%|██████████| 6040/6040 [00:00<00:00, 10631.42it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "799470\n",
      "200739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:04<00:00,  3.60it/s]\n",
      "100%|██████████| 6040/6040 [00:00<00:00, 10411.46it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800322\n",
      "199887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:04<00:00,  3.58it/s]\n",
      "100%|██████████| 6040/6040 [00:00<00:00, 10393.50it/s]\n"
     ]
    }
   ],
   "source": [
    "res = cross_validation.k_fold_eval(test, train, als, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>map</th>\n",
       "      <th>ndcg</th>\n",
       "      <th>auc</th>\n",
       "      <th>mpr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>metrics@10</th>\n",
       "      <td>0.337152</td>\n",
       "      <td>0.223396</td>\n",
       "      <td>0.352792</td>\n",
       "      <td>0.518282</td>\n",
       "      <td>0.273166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metrics@10</th>\n",
       "      <td>0.409255</td>\n",
       "      <td>0.290524</td>\n",
       "      <td>0.429415</td>\n",
       "      <td>0.524248</td>\n",
       "      <td>0.245237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metrics@10</th>\n",
       "      <td>0.425702</td>\n",
       "      <td>0.305386</td>\n",
       "      <td>0.446282</td>\n",
       "      <td>0.525916</td>\n",
       "      <td>0.242163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metrics@10</th>\n",
       "      <td>0.427036</td>\n",
       "      <td>0.304302</td>\n",
       "      <td>0.445478</td>\n",
       "      <td>0.526293</td>\n",
       "      <td>0.243306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metrics@10</th>\n",
       "      <td>0.421987</td>\n",
       "      <td>0.302089</td>\n",
       "      <td>0.443107</td>\n",
       "      <td>0.525523</td>\n",
       "      <td>0.245361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            precision       map      ndcg       auc       mpr\n",
       "metrics@10   0.337152  0.223396  0.352792  0.518282  0.273166\n",
       "metrics@10   0.409255  0.290524  0.429415  0.524248  0.245237\n",
       "metrics@10   0.425702  0.305386  0.446282  0.525916  0.242163\n",
       "metrics@10   0.427036  0.304302  0.445478  0.526293  0.243306\n",
       "metrics@10   0.421987  0.302089  0.443107  0.525523  0.245361"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5d12259fae5b28c6154b1142ab47a20fd9a5ed96dba143a66549a6b78840fa71"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
