{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import recometrics\n",
    "import implicit\n",
    "from scipy.sparse import coo_matrix\n",
    "import implicit.evaluation\n",
    "from implicit.evaluation import mean_average_precision_at_k\n",
    "from implicit.evaluation import train_test_split\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [1,3,2,3,4,2,5,6,3,8,4,5,3,4,7,6,4,8,1,4,3,6,7,5,4,3,3,5,5,7,1,3,4,3,2]\n",
    "rows = [0,0,0,0,0,1,1,1,1,1,2,2,2,2,2,3,3,3,3,3,4,4,4,4,4,5,5,5,5,5,6,6,6,6,6]\n",
    "cols = [0,1,5,3,2,6,2,3,0,5,0,6,5,1,4,3,1,6,5,2,0,4,3,6,1,2,1,4,0,3,1,3,5,6,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_coo = coo_matrix((data, (rows, cols)), shape=(7, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_train, t_test, t_users_test = \\\n",
    "    recometrics.split_reco_train_test(\n",
    "        test_coo, split_type=\"joined\",\n",
    "        users_test_fraction = None,\n",
    "        max_test_users = 2,\n",
    "        items_test_fraction = 0.3\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = AlternatingLeastSquares(factors=10, regularization=0.1, iterations=20, num_threads=4)\n",
    "test_model.fit(20 * t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_train_data = t_train[:t_test.shape[0]]\n",
    "t_test_data = t_test\n",
    "t_user_factors = test_model.user_factors[:t_test.shape[0]]\n",
    "t_item_factors = test_model.item_factors\n",
    "t_train_data.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs = test_model.recommend(user_items=t_train_data, userid=list(range(0,t_train_data.shape[0])), filter_already_liked_items=True, N = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MPF evaluation function testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for idx, u in enumerate(test_data.toarray()) :\n",
    "zähler_liste = []\n",
    "nenner_liste = []\n",
    "for u in np.unique(t_test_data.tocoo().row) :\n",
    "    #mask = (t_train_data[u].toarray()[0] == 0)\n",
    "    #pred_temp = []\n",
    "    #for i in t_item_factors :\n",
    "    #    pred_temp.append(np.inner(t_user_factors[u], i)) # training beobachtungen auslassen. Pro user die trainings items aus train_data weglassen\n",
    "    recs = test_model.recommend(user_items=t_train_data, userid=list(range(0,t_train_data.shape[0])), filter_already_liked_items=True, N = 4)\n",
    "    pred_temp = recs[1][u]\n",
    "    r = t_test_data[u].toarray()[0][recs[0][u]]\n",
    "    df = pd.DataFrame({'r' : r, 'pred' : pred_temp})\n",
    "    df = df.sort_values(by=['pred'], ascending=False)\n",
    "    index = list(range(0,len(df)))\n",
    "    df['rankui'] = [x / (len(df)-1) for x in index]\n",
    "    zähler_liste.append(np.inner(df.r, df.rankui))\n",
    "    nenner_liste.append(sum(df.r))\n",
    "    mpr_list = [m/n for m, n in zip(zähler_liste, nenner_liste)]\n",
    "    name = 'MPR@' + str(k)\n",
    "    res = pd.DataFrame({name : mpr_list})\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MPR function\n",
    "def MPR(model, train_data, test_data, user_f, item_f, k) :\n",
    "    zähler_liste = []\n",
    "    nenner_liste = []\n",
    "    #for idx, u in enumerate(test_data.toarray()) :\n",
    "    for u in np.unique(test_data.tocoo().row) :\n",
    "        #mask = (train_data[u].toarray()[0] == 0)\n",
    "        #pred_temp = []\n",
    "        #for i in item_f[mask] :\n",
    "        #    pred_temp.append(np.inner(user_f[u], i)) # training beobachtungen auslassen. Pro user die trainings items aus train_data weglassen\n",
    "        #df = pd.DataFrame({'r' : test_data[u].toarray()[0][mask], 'pred' : pred_temp}) #, 'train' : train_data[u].toarray()[0][mask]})\n",
    "        recs = model.recommend(user_items=train_data, userid=list(range(0,train_data.shape[0])), filter_already_liked_items=True, N = k)\n",
    "        pred_temp = recs[1][u]\n",
    "        r = test_data[u].toarray()[0][recs[0][u]]\n",
    "        r = np.clip(r, a_min=0, a_max=1)\n",
    "        df = pd.DataFrame({'r' : r, 'pred' : pred_temp})\n",
    "        df = df.sort_values(by=['pred'], ascending=False)\n",
    "        #df = df.drop(df[df.train > 0].index)\n",
    "        index = list(range(0,len(df)))\n",
    "        df['rankui'] = [x / (len(df)-1) for x in index]\n",
    "        #df = df.iloc[:k, ]\n",
    "        zähler_liste.append(np.inner(df.r, df.rankui))\n",
    "        if sum(df.r) != 0:\n",
    "            nenner_liste.append(sum(df.r))\n",
    "        else:\n",
    "            nenner_liste.append(1)\n",
    "        if u % 100 == 0:\n",
    "            print(u)\n",
    "    mpr_list = [m/n for m, n in zip(zähler_liste, nenner_liste)]\n",
    "    name = 'MPR@' + str(k)\n",
    "    return pd.DataFrame({name : mpr_list})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MPR(test_model, t_train_data, t_test_data, t_user_factors, t_item_factors, 4)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
