{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code snippets that might be useful for iALS modeling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for loading lastfm data automatically\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix, csr_matrix\n",
    "\n",
    "from implicit.datasets import _download\n",
    "\n",
    "log = logging.getLogger(\"implicit\")\n",
    "\n",
    "\n",
    "URL = \"https://github.com/benfred/recommender_data/releases/download/v1.0/lastfm_360k.hdf5\"\n",
    "\n",
    "\n",
    "def get_lastfm():\n",
    "    \"\"\"Returns the lastfm360k dataset, downloading locally if necessary.\n",
    "    Returns a tuple of (artistids, userids, plays) where plays is a CSR matrix\"\"\"\n",
    "\n",
    "    filename = os.path.join(_download.LOCAL_CACHE_DIR, \"lastfm_360k.hdf5\")\n",
    "    if not os.path.isfile(filename):\n",
    "        log.info(\"Downloading dataset to '%s'\", filename)\n",
    "        _download.download_file(URL, filename)\n",
    "    else:\n",
    "        log.info(\"Using cached dataset at '%s'\", filename)\n",
    "\n",
    "    with h5py.File(filename, \"r\") as f:\n",
    "        m = f.get(\"artist_user_plays\")\n",
    "        plays = csr_matrix((m.get(\"data\"), m.get(\"indices\"), m.get(\"indptr\")))\n",
    "        return np.array(f[\"artist\"].asstr()[:]), np.array(f[\"user\"].asstr()[:]), plays\n",
    "\n",
    "\n",
    "def generate_dataset(filename, outputfilename):\n",
    "    \"\"\"Generates a hdf5 lastfm datasetfile from the raw datafiles found at:\n",
    "    http://ocelma.net/MusicRecommendationDataset/lastfm-360K.html\n",
    "\n",
    "    You shouldn't have to run this yourself, and can instead just download the\n",
    "    output using the 'get_lastfm' function./\n",
    "\n",
    "    Note there are some invalid entries in this dataset, running\n",
    "    this function will clean it up so pandas can read it:\n",
    "    https://github.com/benfred/bens-blog-code/blob/master/distance-metrics/musicdata.py#L39\n",
    "    \"\"\"\n",
    "    data = _read_dataframe(filename)\n",
    "    _hfd5_from_dataframe(data, outputfilename)\n",
    "\n",
    "\n",
    "def _read_dataframe(filename):\n",
    "    \"\"\"Reads the original dataset TSV as a pandas dataframe\"\"\"\n",
    "    # delay importing this to avoid another dependency\n",
    "    import pandas\n",
    "\n",
    "    # read in triples of user/artist/playcount from the input dataset\n",
    "    # get a model based off the input params\n",
    "    start = time.time()\n",
    "    log.debug(\"reading data from %s\", filename)\n",
    "    data = pandas.read_table(\n",
    "        filename, usecols=[0, 2, 3], names=[\"user\", \"artist\", \"plays\"], na_filter=False\n",
    "    )\n",
    "\n",
    "    # map each artist and user to a unique numeric value\n",
    "    data[\"user\"] = data[\"user\"].astype(\"category\")\n",
    "    data[\"artist\"] = data[\"artist\"].astype(\"category\")\n",
    "\n",
    "    # store as a CSR matrix\n",
    "    log.debug(\"read data file in %s\", time.time() - start)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def _hfd5_from_dataframe(data, outputfilename):\n",
    "    # create a sparse matrix of all the users/plays\n",
    "    plays = coo_matrix(\n",
    "        (\n",
    "            data[\"plays\"].astype(np.float32),\n",
    "            (data[\"user\"].cat.codes.copy(), data[\"artist\"].cat.codes.copy()),\n",
    "        )\n",
    "    ).tocsr()\n",
    "\n",
    "    with h5py.File(outputfilename, \"w\") as f:\n",
    "        g = f.create_group(\"artist_user_plays\")\n",
    "        g.create_dataset(\"data\", data=plays.data)\n",
    "        g.create_dataset(\"indptr\", data=plays.indptr)\n",
    "        g.create_dataset(\"indices\", data=plays.indices)\n",
    "\n",
    "        dt = h5py.special_dtype(vlen=str)\n",
    "        artist = list(data[\"artist\"].cat.categories)\n",
    "        dset = f.create_dataset(\"artist\", (len(artist),), dtype=dt)\n",
    "        dset[:] = artist\n",
    "\n",
    "        user = list(data[\"user\"].cat.categories)\n",
    "        dset = f.create_dataset(\"user\", (len(user),), dtype=dt)\n",
    "        dset[:] = user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Import from lasftfm 360k\n",
    "import fun: data=get_lastfm()\n",
    "output: \n",
    "artists = data[0]\n",
    "users = data[1]\n",
    "plays = data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#possible parameter grid for iALS\n",
    "factors = [20, 40, 60, 80, 100, 120, 140, 160, 180, 200]\n",
    "factors_s = [20, 40, 60]\n",
    "regularization = [0.1, 0.03, 0.01, 0.003, 0.001, 0.0003]\n",
    "alpha = [20, 30, 40, 50, 60]\n",
    "iterations = [10, 20, 30]\n",
    "k = [2, 5, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5d12259fae5b28c6154b1142ab47a20fd9a5ed96dba143a66549a6b78840fa71"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
