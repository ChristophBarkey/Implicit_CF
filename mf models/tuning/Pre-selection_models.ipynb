{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook for Pre-selection of models. For this purpose a shallow train/test evaluation protocol is applied:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dataloading import DataLoader\n",
    "from eda_py import EDA\n",
    "from eALS_adaptor import eALSAdaptor\n",
    "from implicit.evaluation import train_test_split, ranking_metrics_at_k\n",
    "from cv_py import CrossValidation\n",
    "\n",
    "%cd C:\\Users\\781110104\\OneDrive - Genpact\\Documents\\VSCode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item_co = dl.import_data('AGCO', 'CO', 'df')\n",
    "user_item_co_t = dl.import_data('TEREX', 'CO', 'df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item_filtered = dl.remove_low_interact_items(user_item_co, 1)\n",
    "user_item_filtered_t = dl.remove_low_interact_items(user_item_co_t, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item_filtered_log = dl.log_scale_df(user_item_filtered, 0.01)\n",
    "user_item_filtered_log_t = dl.log_scale_df(user_item_filtered_t, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item_csr = dl.to_csr(user_item_filtered_log)\n",
    "user_item_csr_t = dl.to_csr(user_item_filtered_log_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(user_item_csr, 0.8, 22)\n",
    "train_t, test_t = train_test_split(user_item_csr_t, 0.8, 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CrossValidation(user_item_csr, 5)\n",
    "cv_t = CrossValidation(user_item_csr_t, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\781110104\\Anaconda3\\lib\\site-packages\\implicit\\utils.py:33: UserWarning: Intel MKL BLAS detected. Its highly recommend to set the environment variable 'export MKL_NUM_THREADS=1' to disable its internal multithreading\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "space_iALS = {'factors' : [64], 'regularization' : [60, 80, 100, 120], 'alpha' : [0.1, 0.2, 0.3, 0.4, 0.5], 'iterations' : [15]}\n",
    "space_iALS_t = {'factors' : [64], 'regularization' : [60, 80, 100, 120], 'alpha' : [0.3, 0.4, 0.5, 0.6, 0.7], 'iterations' : [15]}\n",
    "hyper_ials = cv.hyperp_tuning_simple(test=test, train=train, seed=22, param_space=space_iALS, model_class='iALS')\n",
    "hyper_ials_t = cv_t.hyperp_tuning_simple(test=test_t, train=train_t, seed=22, param_space=space_iALS_t, model_class='iALS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>factors</th>\n",
       "      <th>regularization</th>\n",
       "      <th>alpha</th>\n",
       "      <th>iterations</th>\n",
       "      <th>precision</th>\n",
       "      <th>map</th>\n",
       "      <th>ndcg</th>\n",
       "      <th>auc</th>\n",
       "      <th>mpr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64</td>\n",
       "      <td>60</td>\n",
       "      <td>0.6</td>\n",
       "      <td>15</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.492189</td>\n",
       "      <td>0.615407</td>\n",
       "      <td>0.513700</td>\n",
       "      <td>0.105059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64</td>\n",
       "      <td>60</td>\n",
       "      <td>0.7</td>\n",
       "      <td>15</td>\n",
       "      <td>0.5950</td>\n",
       "      <td>0.485532</td>\n",
       "      <td>0.609501</td>\n",
       "      <td>0.513683</td>\n",
       "      <td>0.104252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>64</td>\n",
       "      <td>80</td>\n",
       "      <td>0.7</td>\n",
       "      <td>15</td>\n",
       "      <td>0.5875</td>\n",
       "      <td>0.482107</td>\n",
       "      <td>0.609961</td>\n",
       "      <td>0.513854</td>\n",
       "      <td>0.105117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64</td>\n",
       "      <td>60</td>\n",
       "      <td>0.5</td>\n",
       "      <td>15</td>\n",
       "      <td>0.5850</td>\n",
       "      <td>0.486420</td>\n",
       "      <td>0.610880</td>\n",
       "      <td>0.513374</td>\n",
       "      <td>0.106705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>64</td>\n",
       "      <td>80</td>\n",
       "      <td>0.6</td>\n",
       "      <td>15</td>\n",
       "      <td>0.5700</td>\n",
       "      <td>0.466846</td>\n",
       "      <td>0.591967</td>\n",
       "      <td>0.512733</td>\n",
       "      <td>0.107891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>64</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>15</td>\n",
       "      <td>0.5525</td>\n",
       "      <td>0.447601</td>\n",
       "      <td>0.569747</td>\n",
       "      <td>0.512344</td>\n",
       "      <td>0.109149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64</td>\n",
       "      <td>60</td>\n",
       "      <td>0.4</td>\n",
       "      <td>15</td>\n",
       "      <td>0.5425</td>\n",
       "      <td>0.441904</td>\n",
       "      <td>0.568991</td>\n",
       "      <td>0.511896</td>\n",
       "      <td>0.108931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>64</td>\n",
       "      <td>80</td>\n",
       "      <td>0.5</td>\n",
       "      <td>15</td>\n",
       "      <td>0.5250</td>\n",
       "      <td>0.424213</td>\n",
       "      <td>0.546535</td>\n",
       "      <td>0.511503</td>\n",
       "      <td>0.110690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>64</td>\n",
       "      <td>120</td>\n",
       "      <td>0.7</td>\n",
       "      <td>15</td>\n",
       "      <td>0.5225</td>\n",
       "      <td>0.417505</td>\n",
       "      <td>0.536843</td>\n",
       "      <td>0.511433</td>\n",
       "      <td>0.116346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>64</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>15</td>\n",
       "      <td>0.5200</td>\n",
       "      <td>0.416385</td>\n",
       "      <td>0.536267</td>\n",
       "      <td>0.511481</td>\n",
       "      <td>0.113558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>64</td>\n",
       "      <td>120</td>\n",
       "      <td>0.6</td>\n",
       "      <td>15</td>\n",
       "      <td>0.5175</td>\n",
       "      <td>0.407608</td>\n",
       "      <td>0.531680</td>\n",
       "      <td>0.511266</td>\n",
       "      <td>0.122930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>64</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>15</td>\n",
       "      <td>0.5175</td>\n",
       "      <td>0.409973</td>\n",
       "      <td>0.533210</td>\n",
       "      <td>0.511238</td>\n",
       "      <td>0.121175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>64</td>\n",
       "      <td>80</td>\n",
       "      <td>0.4</td>\n",
       "      <td>15</td>\n",
       "      <td>0.5150</td>\n",
       "      <td>0.402791</td>\n",
       "      <td>0.526625</td>\n",
       "      <td>0.511284</td>\n",
       "      <td>0.118376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>64</td>\n",
       "      <td>120</td>\n",
       "      <td>0.5</td>\n",
       "      <td>15</td>\n",
       "      <td>0.5125</td>\n",
       "      <td>0.400017</td>\n",
       "      <td>0.524382</td>\n",
       "      <td>0.511146</td>\n",
       "      <td>0.125195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64</td>\n",
       "      <td>60</td>\n",
       "      <td>0.3</td>\n",
       "      <td>15</td>\n",
       "      <td>0.5075</td>\n",
       "      <td>0.399859</td>\n",
       "      <td>0.526984</td>\n",
       "      <td>0.511252</td>\n",
       "      <td>0.114441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>64</td>\n",
       "      <td>120</td>\n",
       "      <td>0.4</td>\n",
       "      <td>15</td>\n",
       "      <td>0.5050</td>\n",
       "      <td>0.399373</td>\n",
       "      <td>0.529774</td>\n",
       "      <td>0.511618</td>\n",
       "      <td>0.148517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>64</td>\n",
       "      <td>100</td>\n",
       "      <td>0.4</td>\n",
       "      <td>15</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.392321</td>\n",
       "      <td>0.515409</td>\n",
       "      <td>0.510880</td>\n",
       "      <td>0.126176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>64</td>\n",
       "      <td>80</td>\n",
       "      <td>0.3</td>\n",
       "      <td>15</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.390589</td>\n",
       "      <td>0.519845</td>\n",
       "      <td>0.510948</td>\n",
       "      <td>0.128582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>64</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3</td>\n",
       "      <td>15</td>\n",
       "      <td>0.2725</td>\n",
       "      <td>0.216084</td>\n",
       "      <td>0.296073</td>\n",
       "      <td>0.505578</td>\n",
       "      <td>0.160984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>64</td>\n",
       "      <td>120</td>\n",
       "      <td>0.3</td>\n",
       "      <td>15</td>\n",
       "      <td>0.2700</td>\n",
       "      <td>0.214032</td>\n",
       "      <td>0.291156</td>\n",
       "      <td>0.505433</td>\n",
       "      <td>0.177745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    factors  regularization  alpha  iterations  precision       map      ndcg  \\\n",
       "3        64              60    0.6          15     0.6000  0.492189  0.615407   \n",
       "4        64              60    0.7          15     0.5950  0.485532  0.609501   \n",
       "9        64              80    0.7          15     0.5875  0.482107  0.609961   \n",
       "2        64              60    0.5          15     0.5850  0.486420  0.610880   \n",
       "8        64              80    0.6          15     0.5700  0.466846  0.591967   \n",
       "14       64             100    0.7          15     0.5525  0.447601  0.569747   \n",
       "1        64              60    0.4          15     0.5425  0.441904  0.568991   \n",
       "7        64              80    0.5          15     0.5250  0.424213  0.546535   \n",
       "19       64             120    0.7          15     0.5225  0.417505  0.536843   \n",
       "13       64             100    0.6          15     0.5200  0.416385  0.536267   \n",
       "18       64             120    0.6          15     0.5175  0.407608  0.531680   \n",
       "12       64             100    0.5          15     0.5175  0.409973  0.533210   \n",
       "6        64              80    0.4          15     0.5150  0.402791  0.526625   \n",
       "17       64             120    0.5          15     0.5125  0.400017  0.524382   \n",
       "0        64              60    0.3          15     0.5075  0.399859  0.526984   \n",
       "16       64             120    0.4          15     0.5050  0.399373  0.529774   \n",
       "11       64             100    0.4          15     0.5000  0.392321  0.515409   \n",
       "5        64              80    0.3          15     0.5000  0.390589  0.519845   \n",
       "10       64             100    0.3          15     0.2725  0.216084  0.296073   \n",
       "15       64             120    0.3          15     0.2700  0.214032  0.291156   \n",
       "\n",
       "         auc       mpr  \n",
       "3   0.513700  0.105059  \n",
       "4   0.513683  0.104252  \n",
       "9   0.513854  0.105117  \n",
       "2   0.513374  0.106705  \n",
       "8   0.512733  0.107891  \n",
       "14  0.512344  0.109149  \n",
       "1   0.511896  0.108931  \n",
       "7   0.511503  0.110690  \n",
       "19  0.511433  0.116346  \n",
       "13  0.511481  0.113558  \n",
       "18  0.511266  0.122930  \n",
       "12  0.511238  0.121175  \n",
       "6   0.511284  0.118376  \n",
       "17  0.511146  0.125195  \n",
       "0   0.511252  0.114441  \n",
       "16  0.511618  0.148517  \n",
       "11  0.510880  0.126176  \n",
       "5   0.510948  0.128582  \n",
       "10  0.505578  0.160984  \n",
       "15  0.505433  0.177745  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_ials_t.sort_values(by=['precision'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\781110104\\OneDrive - Genpact\\Documents\\VSCode\\implicit repo\\Implicit_CF\\cv_py.py:443\u001b[0m, in \u001b[0;36mCrossValidation.hyperp_tuning_simple\u001b[1;34m(self, test, train, seed, param_space, model_class)\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 443\u001b[0m     model\u001b[39m.\u001b[39;49mfit(train, show_progress\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    445\u001b[0m \u001b[39m# if Nan appears in factors, they are transformed to 0 and the param combination printed out\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: fit() got an unexpected keyword argument 'show_progress'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\781110104\\OneDrive - Genpact\\Documents\\VSCode\\implicit repo\\Implicit_CF\\Pre-selection_models.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/781110104/OneDrive%20-%20Genpact/Documents/VSCode/implicit%20repo/Implicit_CF/Pre-selection_models.ipynb#ch0000011?line=0'>1</a>\u001b[0m space_eALS \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mfactors\u001b[39m\u001b[39m'\u001b[39m : [\u001b[39m64\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mregularization\u001b[39m\u001b[39m'\u001b[39m : [\u001b[39m5\u001b[39m, \u001b[39m10\u001b[39m, \u001b[39m20\u001b[39m], \u001b[39m'\u001b[39m\u001b[39malpha\u001b[39m\u001b[39m'\u001b[39m : [\u001b[39m0.5\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mw0\u001b[39m\u001b[39m'\u001b[39m : [\u001b[39m20\u001b[39m, \u001b[39m30\u001b[39m, \u001b[39m40\u001b[39m, \u001b[39m50\u001b[39m, \u001b[39m60\u001b[39m]}\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/781110104/OneDrive%20-%20Genpact/Documents/VSCode/implicit%20repo/Implicit_CF/Pre-selection_models.ipynb#ch0000011?line=1'>2</a>\u001b[0m space_eALS_t \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mfactors\u001b[39m\u001b[39m'\u001b[39m : [\u001b[39m64\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mregularization\u001b[39m\u001b[39m'\u001b[39m : [\u001b[39m0.5\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m5\u001b[39m, \u001b[39m10\u001b[39m], \u001b[39m'\u001b[39m\u001b[39malpha\u001b[39m\u001b[39m'\u001b[39m : [\u001b[39m0.2\u001b[39m, \u001b[39m0.3\u001b[39m, \u001b[39m0.5\u001b[39m, \u001b[39m1\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mw0\u001b[39m\u001b[39m'\u001b[39m : [\u001b[39m20\u001b[39m, \u001b[39m30\u001b[39m, \u001b[39m40\u001b[39m, \u001b[39m50\u001b[39m]}\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/781110104/OneDrive%20-%20Genpact/Documents/VSCode/implicit%20repo/Implicit_CF/Pre-selection_models.ipynb#ch0000011?line=2'>3</a>\u001b[0m hyper_eals \u001b[39m=\u001b[39m cv\u001b[39m.\u001b[39;49mhyperp_tuning_simple(test\u001b[39m=\u001b[39;49mtest, train\u001b[39m=\u001b[39;49mtrain, seed\u001b[39m=\u001b[39;49m\u001b[39m22\u001b[39;49m, param_space\u001b[39m=\u001b[39;49mspace_eALS, model_class\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39meALS\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/781110104/OneDrive%20-%20Genpact/Documents/VSCode/implicit%20repo/Implicit_CF/Pre-selection_models.ipynb#ch0000011?line=3'>4</a>\u001b[0m hyper_eals_t \u001b[39m=\u001b[39m cv_t\u001b[39m.\u001b[39mhyperp_tuning_simple(test\u001b[39m=\u001b[39mtest_t, train\u001b[39m=\u001b[39mtrain_t, seed\u001b[39m=\u001b[39m\u001b[39m22\u001b[39m, param_space\u001b[39m=\u001b[39mspace_eALS_t, model_class\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39meALS\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\781110104\\OneDrive - Genpact\\Documents\\VSCode\\implicit repo\\Implicit_CF\\cv_py.py:447\u001b[0m, in \u001b[0;36mCrossValidation.hyperp_tuning_simple\u001b[1;34m(self, test, train, seed, param_space, model_class)\u001b[0m\n\u001b[0;32m    445\u001b[0m \u001b[39m# if Nan appears in factors, they are transformed to 0 and the param combination printed out\u001b[39;00m\n\u001b[0;32m    446\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m--> 447\u001b[0m     model\u001b[39m.\u001b[39muser_factors[np\u001b[39m.\u001b[39;49misnan(model\u001b[39m.\u001b[39;49muser_factors)] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m    448\u001b[0m     model\u001b[39m.\u001b[39mitem_factors[np\u001b[39m.\u001b[39misnan(model\u001b[39m.\u001b[39mitem_factors)] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m    449\u001b[0m     \u001b[39mprint\u001b[39m(r)\n",
      "\u001b[1;31mTypeError\u001b[0m: ufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
     ]
    }
   ],
   "source": [
    "space_eALS = {'factors' : [64], 'regularization' : [5, 10, 20], 'alpha' : [0.5, 1, 2], 'w0' : [20, 30, 40, 50, 60]}\n",
    "space_eALS_t = {'factors' : [64], 'regularization' : [1, 5, 10], 'alpha' : [0.3, 0.5, 1, 2], 'w0' : [20, 30, 40, 50, 60]}\n",
    "hyper_eals = cv.hyperp_tuning_simple(test=test, train=train, seed=22, param_space=space_eALS, model_class='eALS')\n",
    "hyper_eals_t = cv_t.hyperp_tuning_simple(test=test_t, train=train_t, seed=22, param_space=space_eALS_t, model_class='eALS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_BPR = {'factors' : [64], 'regularization' : [0.01, 0.05, 0.1], 'learning_rate' : [0.005, 0.01, 0.03, 0.05], 'iterations' : [15]}\n",
    "space_BPR_t = {'factors' : [64], 'regularization' : [0.01, 0.05, 0.07, 0.1], 'learning_rate' : [0.01, 0.03, 0.04, 0.05], 'iterations' : [15]}\n",
    "hyper_bpr = cv.hyperp_tuning_simple(test=test, train=train, seed=22, param_space=space_BPR, model_class='BPR')\n",
    "hyper_bpr_t = cv_t.hyperp_tuning_simple(test=test_t, train=train_t, seed=22, param_space=space_BPR_t, model_class='BPR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>factors</th>\n",
       "      <th>regularization</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>iterations</th>\n",
       "      <th>precision</th>\n",
       "      <th>map</th>\n",
       "      <th>ndcg</th>\n",
       "      <th>auc</th>\n",
       "      <th>mpr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>64</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.04</td>\n",
       "      <td>15</td>\n",
       "      <td>0.3900</td>\n",
       "      <td>0.256441</td>\n",
       "      <td>0.403107</td>\n",
       "      <td>0.508503</td>\n",
       "      <td>0.116047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>64</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.05</td>\n",
       "      <td>15</td>\n",
       "      <td>0.3875</td>\n",
       "      <td>0.248703</td>\n",
       "      <td>0.397436</td>\n",
       "      <td>0.508647</td>\n",
       "      <td>0.118413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>64</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.03</td>\n",
       "      <td>15</td>\n",
       "      <td>0.3775</td>\n",
       "      <td>0.261830</td>\n",
       "      <td>0.405805</td>\n",
       "      <td>0.508523</td>\n",
       "      <td>0.132994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>64</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>15</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.238101</td>\n",
       "      <td>0.383687</td>\n",
       "      <td>0.507968</td>\n",
       "      <td>0.112722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>64</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.04</td>\n",
       "      <td>15</td>\n",
       "      <td>0.3675</td>\n",
       "      <td>0.251628</td>\n",
       "      <td>0.393997</td>\n",
       "      <td>0.508289</td>\n",
       "      <td>0.130743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>15</td>\n",
       "      <td>0.3650</td>\n",
       "      <td>0.234539</td>\n",
       "      <td>0.377510</td>\n",
       "      <td>0.507725</td>\n",
       "      <td>0.111900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>64</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.03</td>\n",
       "      <td>15</td>\n",
       "      <td>0.3550</td>\n",
       "      <td>0.242092</td>\n",
       "      <td>0.375757</td>\n",
       "      <td>0.507113</td>\n",
       "      <td>0.157160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>64</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>15</td>\n",
       "      <td>0.3550</td>\n",
       "      <td>0.241122</td>\n",
       "      <td>0.374548</td>\n",
       "      <td>0.507521</td>\n",
       "      <td>0.144177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>64</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.04</td>\n",
       "      <td>15</td>\n",
       "      <td>0.3475</td>\n",
       "      <td>0.238117</td>\n",
       "      <td>0.361746</td>\n",
       "      <td>0.507167</td>\n",
       "      <td>0.178801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>15</td>\n",
       "      <td>0.3425</td>\n",
       "      <td>0.214839</td>\n",
       "      <td>0.360217</td>\n",
       "      <td>0.507562</td>\n",
       "      <td>0.110371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>15</td>\n",
       "      <td>0.3325</td>\n",
       "      <td>0.205499</td>\n",
       "      <td>0.347163</td>\n",
       "      <td>0.507539</td>\n",
       "      <td>0.107814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>15</td>\n",
       "      <td>0.2175</td>\n",
       "      <td>0.141698</td>\n",
       "      <td>0.225861</td>\n",
       "      <td>0.503692</td>\n",
       "      <td>0.172692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>64</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.03</td>\n",
       "      <td>15</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.059633</td>\n",
       "      <td>0.136398</td>\n",
       "      <td>0.502280</td>\n",
       "      <td>0.345509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0225</td>\n",
       "      <td>0.009236</td>\n",
       "      <td>0.027268</td>\n",
       "      <td>0.500767</td>\n",
       "      <td>0.385344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>64</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0225</td>\n",
       "      <td>0.009236</td>\n",
       "      <td>0.027268</td>\n",
       "      <td>0.500767</td>\n",
       "      <td>0.387036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>64</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0225</td>\n",
       "      <td>0.008819</td>\n",
       "      <td>0.026547</td>\n",
       "      <td>0.500767</td>\n",
       "      <td>0.387606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    factors  regularization  learning_rate  iterations  precision       map  \\\n",
       "6        64            0.05           0.04          15     0.3900  0.256441   \n",
       "11       64            0.07           0.05          15     0.3875  0.248703   \n",
       "5        64            0.05           0.03          15     0.3775  0.261830   \n",
       "7        64            0.05           0.05          15     0.3750  0.238101   \n",
       "10       64            0.07           0.04          15     0.3675  0.251628   \n",
       "1        64            0.01           0.03          15     0.3650  0.234539   \n",
       "9        64            0.07           0.03          15     0.3550  0.242092   \n",
       "15       64            0.10           0.05          15     0.3550  0.241122   \n",
       "14       64            0.10           0.04          15     0.3475  0.238117   \n",
       "2        64            0.01           0.04          15     0.3425  0.214839   \n",
       "3        64            0.01           0.05          15     0.3325  0.205499   \n",
       "0        64            0.01           0.01          15     0.2175  0.141698   \n",
       "13       64            0.10           0.03          15     0.1250  0.059633   \n",
       "4        64            0.05           0.01          15     0.0225  0.009236   \n",
       "8        64            0.07           0.01          15     0.0225  0.009236   \n",
       "12       64            0.10           0.01          15     0.0225  0.008819   \n",
       "\n",
       "        ndcg       auc       mpr  \n",
       "6   0.403107  0.508503  0.116047  \n",
       "11  0.397436  0.508647  0.118413  \n",
       "5   0.405805  0.508523  0.132994  \n",
       "7   0.383687  0.507968  0.112722  \n",
       "10  0.393997  0.508289  0.130743  \n",
       "1   0.377510  0.507725  0.111900  \n",
       "9   0.375757  0.507113  0.157160  \n",
       "15  0.374548  0.507521  0.144177  \n",
       "14  0.361746  0.507167  0.178801  \n",
       "2   0.360217  0.507562  0.110371  \n",
       "3   0.347163  0.507539  0.107814  \n",
       "0   0.225861  0.503692  0.172692  \n",
       "13  0.136398  0.502280  0.345509  \n",
       "4   0.027268  0.500767  0.385344  \n",
       "8   0.027268  0.500767  0.387036  \n",
       "12  0.026547  0.500767  0.387606  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_bpr_t.sort_values(by=['precision'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_LMF = {'factors' : [64], 'regularization' : [10, 20, 30, 40, 50], 'learning_rate' : [0.3, 0.5, 0.7, 1.0, 2.0], 'iterations' : [15], 'neg_prop': [10, 20, 30]}\n",
    "space_LMF_t = {'factors' : [64], 'regularization' : [10, 20, 30, 40, 50], 'learning_rate' : [0.3, 0.5, 0.7, 1.0, 2.0], 'iterations' : [15], 'neg_prop': [0.5, 1, 2, 5, 10]}\n",
    "hyper_lmf = cv.hyperp_tuning_simple(test=test, train=train, seed=22, param_space=space_LMF, model_class='LMF')\n",
    "hyper_lmf_t = cv_t.hyperp_tuning_simple(test=test_t, train=train_t, seed=22, param_space=space_LMF_t, model_class='LMF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>factors</th>\n",
       "      <th>regularization</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>iterations</th>\n",
       "      <th>neg_prop</th>\n",
       "      <th>precision</th>\n",
       "      <th>map</th>\n",
       "      <th>ndcg</th>\n",
       "      <th>auc</th>\n",
       "      <th>mpr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>64</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4600</td>\n",
       "      <td>0.346414</td>\n",
       "      <td>0.469798</td>\n",
       "      <td>0.510447</td>\n",
       "      <td>0.211272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>64</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3875</td>\n",
       "      <td>0.265012</td>\n",
       "      <td>0.391519</td>\n",
       "      <td>0.508147</td>\n",
       "      <td>0.168905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>64</td>\n",
       "      <td>20</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2725</td>\n",
       "      <td>0.136900</td>\n",
       "      <td>0.256487</td>\n",
       "      <td>0.506580</td>\n",
       "      <td>0.171952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>64</td>\n",
       "      <td>20</td>\n",
       "      <td>0.7</td>\n",
       "      <td>15</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2550</td>\n",
       "      <td>0.136568</td>\n",
       "      <td>0.248284</td>\n",
       "      <td>0.505231</td>\n",
       "      <td>0.172220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>64</td>\n",
       "      <td>40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2550</td>\n",
       "      <td>0.121686</td>\n",
       "      <td>0.225077</td>\n",
       "      <td>0.505348</td>\n",
       "      <td>0.255528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>64</td>\n",
       "      <td>40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0225</td>\n",
       "      <td>0.004964</td>\n",
       "      <td>0.018138</td>\n",
       "      <td>0.500073</td>\n",
       "      <td>0.442797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>64</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.010670</td>\n",
       "      <td>0.027186</td>\n",
       "      <td>0.500089</td>\n",
       "      <td>0.297611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>64</td>\n",
       "      <td>50</td>\n",
       "      <td>0.7</td>\n",
       "      <td>15</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.004625</td>\n",
       "      <td>0.016424</td>\n",
       "      <td>0.499974</td>\n",
       "      <td>0.396915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>64</td>\n",
       "      <td>20</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.005214</td>\n",
       "      <td>0.017547</td>\n",
       "      <td>0.499952</td>\n",
       "      <td>0.470872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>64</td>\n",
       "      <td>40</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.003413</td>\n",
       "      <td>0.010649</td>\n",
       "      <td>0.499839</td>\n",
       "      <td>0.450217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     factors  regularization  learning_rate  iterations  neg_prop  precision  \\\n",
       "65        64              30            1.0          15       0.5     0.4600   \n",
       "40        64              20            1.0          15       0.5     0.3875   \n",
       "45        64              20            2.0          15       0.5     0.2725   \n",
       "35        64              20            0.7          15       0.5     0.2550   \n",
       "90        64              40            1.0          15       0.5     0.2550   \n",
       "..       ...             ...            ...         ...       ...        ...   \n",
       "93        64              40            1.0          15       5.0     0.0225   \n",
       "106       64              50            0.5          15       1.0     0.0200   \n",
       "113       64              50            0.7          15       5.0     0.0200   \n",
       "48        64              20            2.0          15       5.0     0.0200   \n",
       "99        64              40            2.0          15      10.0     0.0100   \n",
       "\n",
       "          map      ndcg       auc       mpr  \n",
       "65   0.346414  0.469798  0.510447  0.211272  \n",
       "40   0.265012  0.391519  0.508147  0.168905  \n",
       "45   0.136900  0.256487  0.506580  0.171952  \n",
       "35   0.136568  0.248284  0.505231  0.172220  \n",
       "90   0.121686  0.225077  0.505348  0.255528  \n",
       "..        ...       ...       ...       ...  \n",
       "93   0.004964  0.018138  0.500073  0.442797  \n",
       "106  0.010670  0.027186  0.500089  0.297611  \n",
       "113  0.004625  0.016424  0.499974  0.396915  \n",
       "48   0.005214  0.017547  0.499952  0.470872  \n",
       "99   0.003413  0.010649  0.499839  0.450217  \n",
       "\n",
       "[125 rows x 10 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_lmf_t.sort_values(by=['precision'], ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b4efcf30d150067e76aa0880eb47772143c44e1fc3c522760740bd759ef99df4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
